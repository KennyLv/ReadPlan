要看你定义的“爬虫”干什么用。

1、如果是定向爬取几个页面，做一些简单的页面解析，爬取效率不是核心要求，那么用什么语言差异不大。
当然要是页面结构复杂，正则表达式写得巨复杂，尤其是用过那些支持xpath的类库/爬虫库后，就会发现此种方式虽然入门门槛低，但扩展性、可维护性等都奇差。因此此种情况下还是推荐采用一些现成的爬虫库，诸如xpath、多线程支持还是必须考虑的因素。

2、如果是定向爬取，且主要目标是解析js动态生成的内容
此时候，页面内容是有js/ajax动态生成的，用普通的请求页面->解析的方法就不管用了，需要借助一个类似firefox、chrome浏览器的js引擎来对页面的js代码做动态解析。
此种情况下，推荐考虑casperJS+phantomjs或slimerJS+phantomjs ，当然诸如selenium之类的也可以考虑。

3、如果爬虫是涉及大规模网站爬取，效率、扩展性、可维护性等是必须考虑的因素时候
大规模爬虫爬取涉及诸多问题：多线程并发、I/O机制、分布式爬取、消息通讯、判重机制、任务调度等等，此时候语言和所用框架的选取就具有极大意义了。
PHP对多线程、异步支持较差，不建议采用。
NodeJS：对一些垂直网站爬取倒可以，但由于分布式爬取、消息通讯等支持较弱，根据自己情况判断。
Python：强烈建议，对以上问题都有较好支持。尤其是Scrapy框架值得作为第一选择。优点诸多：支持xpath；基于twisted，性能不错；有较好的调试工具；
此种情况下，如果还需要做js动态内容的解析，casperjs就不适合了，只有基于诸如chrome V8引擎之类自己做js引擎。
至于C、C++虽然性能不错，但不推荐，尤其是考虑到成本等诸多因素；对于大部分公司还是建议基于一些开源的框架来做，不要自己发明轮子，做一个简单的爬虫容易，但要做一个完备的爬虫挺难的。

像我搭建的微信公众号内容聚合的网站 就是基于Scrapy做的，当然还涉及消息队列等。可以参考下图：

具体内容可以参考 一个任务调度分发服务的架构